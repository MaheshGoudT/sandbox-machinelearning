{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import sklearn.preprocessing\n",
    "import scipy.sparse\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy data for regression\n",
    "\n",
    "tmp_df = pd.DataFrame([['a',1,2],['b',3,4],['a',5,6],['b',7,8],['a',9,10],['b',11,12]])\n",
    "tmp_df.columns = ['c1','c2','c3']\n",
    "categorical_features = ['c1','c2']\n",
    "X_train = X_test = pd.get_dummies(tmp_df[categorical_features])\n",
    "Y_train = Y_test = tmp_df['c3']\n",
    "\n",
    "enc_dict = defaultdict(sklearn.preprocessing.LabelEncoder)\n",
    "ohe = sklearn.preprocessing.OneHotEncoder()\n",
    "tmp_le_df = tmp_df[categorical_features].apply(lambda x : enc_dict[x.name].fit_transform(x))\n",
    "ohe.fit(tmp_le_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maheshgoud/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/maheshgoud/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.027579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  50.000000\n",
       "mean    2.027579\n",
       "std     0.126649\n",
       "min     2.000000\n",
       "25%     2.000000\n",
       "50%     2.000000\n",
       "75%     2.000000\n",
       "max     2.666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample specific uncertainty intervals for regression models\n",
    "\n",
    "# clf = sklearn.linear_model.LinearRegression()\n",
    "# clf.fit(X_train, Y_train)\n",
    "# Y_predictions = clf.predict(X_test)\n",
    "# print(clf.coef_, clf.intercept_)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# ##Train/Test prediction intervals using statsmodel. Use bootstrap or below approaches\n",
    "# #Theory: https://onlinecourses.science.psu.edu/stat414/node/298/\n",
    "# #http://nbviewer.jupyter.org/gist/thatneat/10286720\n",
    "# #https://www.learndatasci.com/tutorials/predicting-housing-prices-linear-regression-using-python-pandas-statsmodels/\n",
    "# #https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n",
    "# #https://stats.stackexchange.com/questions/183230/bootstrapping-confidence-interval-from-a-regression-prediction\n",
    "\n",
    "# Using stats model\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "# re = sm.OLS(Y_train, X_train).fit()\n",
    "# print(re.summary())\n",
    "# print('-'*80)\n",
    "# prstd, iv_l, iv_u = wls_prediction_std(re)\n",
    "# print(prstd, iv_l, iv_u)\n",
    "# print('-'*80)\n",
    "# prstd, iv_l, iv_u = wls_prediction_std(re, X_train.iloc[0:2]) #Test set can be invoked through this approach\n",
    "# print(prstd, iv_l, iv_u)\n",
    "\n",
    "# Using bootstrap \n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "n_estimators = 50\n",
    "model = BaggingRegressor(sklearn.linear_model.LinearRegression(), n_estimators=n_estimators, bootstrap=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Inspecting uncertainty interval for a prediction at sample test point\n",
    "test_sample = np.array([[1,2,3]])\n",
    "res = []\n",
    "for m in model.estimators_:\n",
    "    res.append(m.predict(test_sample))\n",
    "pd.DataFrame(res).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maheshgoud/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test shape: (6, 2) (6, 2)\n",
      "c1 2\n",
      "c2 6\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 5)         10          c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 5)         30          c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 10)        0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_one (Reshape)           (None, 10)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           704         reshape_one[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,857\n",
      "Trainable params: 2,857\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maheshgoud/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 1 samples\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 99.7596 - val_loss: 99.9103\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 602us/step - loss: 99.4161 - val_loss: 99.7965\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 605us/step - loss: 99.1371 - val_loss: 99.6767\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 596us/step - loss: 98.6875 - val_loss: 99.5423\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 749us/step - loss: 98.3369 - val_loss: 99.3850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.10295776153605"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding based Neural Network Regressor. Check out https://www.kaggle.com/aquatic/entity-embedding-neural-net\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Input, Embedding, merge, Reshape, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "categorical_features = ['c1','c2']\n",
    "numeric_features = []\n",
    "predict_col_name = 'c3'\n",
    "all_cols = categorical_features\n",
    "\n",
    "## Reformatting train/test data for keras model\n",
    "\n",
    "tmp_X_train, tmp_X_test = tmp_df, tmp_df\n",
    "tmp_le_train_df = tmp_X_train[categorical_features].apply(lambda x: enc_dict[x.name].transform(x))\n",
    "tmp_le_test_df = tmp_X_test[categorical_features].apply(lambda x: enc_dict[x.name].transform(x))\n",
    "\n",
    "tmp_X_train_inp = []\n",
    "tmp_X_test_inp = []\n",
    "for c in all_cols:\n",
    "    tmp_X_train_inp.append(np.array(tmp_le_train_df[c]))\n",
    "    tmp_X_test_inp.append(np.array(tmp_le_test_df[c]))\n",
    "\n",
    "print('Train test shape:', tmp_le_train_df.shape, tmp_le_test_df.shape)\n",
    "tmp_num_feat = {}\n",
    "for col in categorical_features:\n",
    "    num_uniq_features = len(enc_dict[col].classes_)\n",
    "    print (col, num_uniq_features)\n",
    "    tmp_num_feat.update({col:num_uniq_features})  # Feature embedding based regression model using keras\n",
    "\n",
    "embedding_size = 5\n",
    "batch_size = 16\n",
    "\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=0)\n",
    "# tmp_model_save_dir = '/Users/maheshgoud/Desktop/'\n",
    "# tmp_model_save_filename = tmp_model_save_dir + 'model_tmp.h5'\n",
    "\n",
    "## Keras model implementation\n",
    "\n",
    "tmp_input_list = []\n",
    "tmp_embedding_list = []\n",
    "for idx, e_col in enumerate(all_cols):\n",
    "    tmp_input = Input(shape=(1,), dtype='int32', name=e_col)\n",
    "    tmp_embedding = Embedding(input_dim=tmp_num_feat[e_col], output_dim=embedding_size, input_length=1)(tmp_input)\n",
    "    tmp_input_list.append(tmp_input)\n",
    "    tmp_embedding_list.append(tmp_embedding)\n",
    "\n",
    "x = layers.concatenate(tmp_embedding_list)\n",
    "x = Reshape((len(tmp_embedding_list)*embedding_size,), name=\"reshape_one\")(x)\n",
    "x = Dense(64, activation='relu', name=\"dense_1\")(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(32, activation='relu', name=\"dense_2\")(x)\n",
    "tmp_model_output = Dense(1, activation='relu', name=\"dense_3\")(x)\n",
    "\n",
    "tmp_final_model = Model(input=tmp_input_list, output=tmp_model_output)\n",
    "print(tmp_final_model.summary())\n",
    "\n",
    "# mean_squared_error, mean_absolute_percentage_error, mean_squared_logarithmic_error\n",
    "tmp_final_model.compile(loss='mean_absolute_percentage_error', optimizer='adadelta') #metrics=['accuracy']\n",
    "tmp_final_model.fit(tmp_X_train_inp, Y_train.values, epochs=5, batch_size=batch_size, validation_split=0.1) #, callbacks=[early_stopping])\n",
    "\n",
    "# tmp_final_model.save(tmp_model_save_filename)\n",
    "\n",
    "Y_predictions = tmp_final_model.predict(tmp_X_test_inp, batch_size=batch_size)\n",
    "mean_absolute_percentage_error(Y_test.values, Y_predictions) #TODO: Double check\n",
    "\n",
    "# from ann_visualizer.visualize import ann_viz\n",
    "# ann_viz(tmp_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy data for classification\n",
    "\n",
    "tmp_df = pd.DataFrame([['a',1,0],['b',3,1],['a',5,0],['b',7,1],['a',9,0],['b',11,1]])\n",
    "tmp_df.columns = ['c1','c2','c3']\n",
    "categorical_features = ['c1','c2']\n",
    "\n",
    "X_train = X_test = pd.get_dummies(tmp_df[categorical_features])\n",
    "Y_train = Y_test = tmp_df['c3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        (0)       1.00      1.00      1.00         3\n",
      "        (1)       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         6\n",
      "\n",
      "ConfusionMatrix\n",
      " [[3 0]\n",
      " [0 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1_b</td>\n",
       "      <td>7.991014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2</td>\n",
       "      <td>0.085760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1_a</td>\n",
       "      <td>-8.325591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat      coef\n",
       "2  c1_b  7.991014\n",
       "0    c2  0.085760\n",
       "1  c1_a -8.325591"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model evaluation on single train/test split for inspecting confusion matrix\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=1e4)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "\n",
    "#Evaluate predictions\n",
    "score = 100.0*round(clf.score(X_test, Y_test),4)\n",
    "print('Accuracy:',score)\n",
    "print(sklearn.metrics.classification_report(Y_test, Y_predictions, target_names=['(0)','(1)']))\n",
    "cm = sklearn.metrics.confusion_matrix(Y_test, Y_predictions)\n",
    "print('ConfusionMatrix\\n',cm)\n",
    "\n",
    "#Color coded confusion matrix\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(title, size = 15)\n",
    "plt.show()\n",
    "\n",
    "#scikitplot can be used for roc curves. skipping for now\n",
    "\n",
    "# #Precision/Recall curve\n",
    "# y_scores = sklearn.model_selection.cross_val_predict(clf, X_train, Y_train, cv=3, method=\"decision_function\")\n",
    "# precisions, recalls, thresholds = sklearn.metrics.precision_recall_curve(Y_train, y_scores)\n",
    "\n",
    "#Inspect model coefficients\n",
    "print('Model coefficients:')\n",
    "pd.DataFrame({'feat':X_train.columns,'coef':clf.coef_[0]}).sort_values(by=['coef'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c510616acffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#Create train/test lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0membed_and_num_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_and_num_test_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_feat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0membed_and_num_train_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_without_ohe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0membed_and_num_test_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_without_ohe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_feat' is not defined"
     ]
    }
   ],
   "source": [
    "#Categorical embedding + numerical data neural network classifier\n",
    "\n",
    "#Embedding based neural network\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, merge, Reshape, Dropout, Input, Flatten, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_embeddingnetwork(df, categorical_cols, numeric_cols, timestamp_cols=None): \n",
    "    inputs, embeddings = [], []\n",
    "    for c in categorical_cols:\n",
    "        #Determined embedding dimension\n",
    "        no_of_unique_cat  = df[c].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "        embedding_size = int(embedding_size)\n",
    "        #Create embedding\n",
    "        cur_input = Input(shape=(1,), name=c)\n",
    "        cur_embedding = Embedding(no_of_unique_cat+1, embedding_size, input_length=1)(cur_input)\n",
    "        cur_embedding = Reshape(target_shape=(embedding_size,))(cur_embedding)\n",
    "        inputs.append(cur_input)\n",
    "        embeddings.append(cur_embedding)\n",
    "    input_numeric = Input(shape=(len(numeric_cols),))\n",
    "    embedding_numeric = Dense(16)(input_numeric) \n",
    "    inputs.append(input_numeric)\n",
    "    embeddings.append(embedding_numeric)\n",
    "\n",
    "    x = Concatenate()(embeddings)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(.35)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    x = Dense(8, activation='relu')(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#Create train/test lists\n",
    "embed_and_num_train_list, embed_and_num_test_list = [], []\n",
    "for c in cat_feat:\n",
    "    embed_and_num_train_list.append(X_train_without_ohe[c].values)\n",
    "    embed_and_num_test_list.append(X_test_without_ohe[c].values)\n",
    "embed_and_num_train_list.append(X_train_without_ohe[num_feat].values)\n",
    "embed_and_num_test_list.append(X_test_without_ohe[num_feat].values)\n",
    "\n",
    "model = build_embeddingnetwork(X_train_without_ohe, cat_feat, num_feat)\n",
    "print(model.summary())\n",
    "# model.fit(X_train_without_ohe[cat_feat+num_feat], Y_train.values, epochs=50, batch_size=1024, validation_split=0.1, verbose=0)\n",
    "# Y_predictions = model.predict(X_test_without_ohe[cat_feat+num_feat], batch_size=batch_size)\n",
    "model.fit(embed_and_num_train_list, Y_train.values, epochs=10, batch_size=1024, validation_split=0.1, verbose=0)\n",
    "Y_predictions = model.predict(embed_and_num_test_list, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow lr what if ? tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poisson, exp regression with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[10.0000]])), ('linear.bias', tensor([7.7290e-05]))])\n",
      "predict (after training) tensor(39.9999)\n"
     ]
    }
   ],
   "source": [
    "#PyTorch mean squared error regression\n",
    "\n",
    "import torch \n",
    "\n",
    "x1_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y1_data = torch.Tensor([[10.0], [20.0], [30.0]]) #y1=10*x1\n",
    "# x1_data = torch.Tensor([[1.0,2.0], [2.0,3.0], [3.0,4.0]])\n",
    "# y1_data = torch.Tensor([[3.0], [5.0], [7.0]]) #y1=sum(x1)\n",
    "\n",
    "class LinearRegressionModel(torch.nn.Module): \n",
    "    def __init__(self, input_dim, output_dim): \n",
    "        super(LinearRegressionModel, self).__init__() \n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x): \n",
    "        y_pred = self.linear(x) \n",
    "        return y_pred \n",
    "\n",
    "our_model = LinearRegressionModel(1,1) \n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(our_model.parameters(), lr = 0.01) \n",
    "\n",
    "for epoch in range(5000): \n",
    "    pred_y = our_model(x1_data) \n",
    "    loss = criterion(pred_y, y1_data) \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    #print('epoch {}, loss {}'.format(epoch, loss.data)) \n",
    "print(our_model.state_dict())\n",
    " \n",
    "new_var = torch.Tensor([[4.0]])\n",
    "pred_y = our_model(new_var)\n",
    "print(\"predict (after training)\", our_model(new_var).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: OrderedDict([('task1.0.weight', tensor([[ 9.8828, -0.1529]])), ('task2.0.weight', tensor([[-0.3597,  0.3745]]))])\n",
      "Prediction on a test point: (tensor([[11.5077],\n",
      "        [15.4608],\n",
      "        [18.4409],\n",
      "        [13.4536],\n",
      "        [12.4042],\n",
      "        [14.2181],\n",
      "        [13.2910]], grad_fn=<MmBackward>), tensor([[ 0.4296],\n",
      "        [ 0.2857],\n",
      "        [ 0.1403],\n",
      "        [ 0.4325],\n",
      "        [ 0.6183],\n",
      "        [-1.4398],\n",
      "        [-1.5536]], grad_fn=<MmBackward>))\n",
      "Testing without bias: tensor([[0.4333]])\n"
     ]
    }
   ],
   "source": [
    "#PyTorch MSE multi task loss \n",
    "# https://discuss.pytorch.org/t/multi-task-learning-with-adaptive-weights-for-task-losses/24961\n",
    "# https://github.com/huggingface/hmtl\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# x2_data = torch.Tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])\n",
    "# y2_data = torch.Tensor([[10, 3.0], [20, 5.0], [30, 7.0]]) #y2=[10*x2[0], sum(x2)]\n",
    "x2_data = torch.Tensor([[1.2,2.3],[1.6,2.3],[1.9,2.2],[1.4,2.5],[1.3,2.9],[1.4,-2.5],[1.3,-2.9]])\n",
    "y2_data = torch.Tensor([[12,3.5],[16,3.9],[19,4.1],[14,3.9],[13,4.2],[14,-0.1],[13,-1.6]])\n",
    "\n",
    "class MultiTaskModel(nn.Module): \n",
    "    def __init__(self, input_dim, output_dim): \n",
    "        super(MultiTaskModel, self).__init__() \n",
    "        self.task1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1, bias=False),\n",
    "        )\n",
    "        self.task2 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1, bias=False),\n",
    "        )\n",
    "        #self.task1 = self.task2\n",
    "    def forward(self, x): \n",
    "        return self.task1(x), self.task2(x) \n",
    "\n",
    "mt_model = MultiTaskModel(2,1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(mt_model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(10000): \n",
    "    predictions = mt_model(x2_data) \n",
    "    loss = criterion(predictions[0], y2_data[:,0]) #+ criterion(predictions[1], y2_data[:,1]) \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    #print('epoch {}, loss {}'.format(epoch, loss.data)) \n",
    "print(\"Model params:\",mt_model.state_dict())\n",
    "\n",
    "new_var = torch.Tensor([[4.0, 5.0]])\n",
    "print(\"Prediction on a test point:\", mt_model(x2_data))\n",
    "print(\"Testing without bias:\", torch.mm(mt_model.state_dict()['task2.0.weight'], new_var.transpose(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
