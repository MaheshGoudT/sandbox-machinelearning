{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow, PyTorch Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tf.contrib.distributions\n",
    "# tfd = tfp.distributions\n",
    "# tfb = tfp.distributions.bijectors\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "##Helpful links for Distributions\n",
    "# https://arxiv.org/pdf/1711.10604.pdf\n",
    "# https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding%20TensorFlow%20Distributions%20Shapes.ipynb\n",
    "# https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html\n",
    "# https://www.tensorflow.org/api_docs/python/tf/distributions/Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tinker with tf distributions\n",
    "\n",
    "dist = tf.distributions.Normal(loc=0., scale=3.)\n",
    "print(dist.cdf(0.))\n",
    "dist = tf.distributions.Normal(loc=[1, 2.], scale=[11, 22.])\n",
    "# Evaluate the pdf of the first distribution on 0, and the second on 1.5, returning a length two tensor\n",
    "print(dist.prob([0, 1.5]))\n",
    "\n",
    "# Get 3 samples, returning a 3 x 2 tensor.\n",
    "print(dist.sample([3]))\n",
    "print(dist.sample([3]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Tinker with pytorch distributions\n",
    "\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "m = Bernoulli(torch.Tensor([0.3]))\n",
    "r = []\n",
    "for i in range(20):\n",
    "    r.append(m.sample().numpy()[0])\n",
    "print(r)  # 30% chance 1; 70% chance 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Tinker with tf mixture of distributions\n",
    "# https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture\n",
    "\n",
    "mixture_components = [1.0/2]*2\n",
    "bimix_gauss = tfd.Mixture(\n",
    "  cat=tfd.Categorical(probs=mixture_components),\n",
    "  components=[\n",
    "    tfd.Normal(loc=-1., scale=0.1),\n",
    "    tfd.Normal(loc=+1., scale=0.5)\n",
    "])\n",
    "\n",
    "#Is Weibull bijector the only way to directly use weibull distribution in tf ?\n",
    "\n",
    "x = tf.linspace(-2., 3., int(1e4))\n",
    "bimix_gauss.prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Distributions / Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.binomial(10, 0.3, 10))\n",
    "print(np.random.binomial(10, 0.3, 10).mean())\n",
    "\n",
    "print(ss.binom(10, 0.3).rvs(10))\n",
    "print(ss.binom(10, 0.3).cdf(5))\n",
    "print(ss.binom(10, 0.3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using scipy optimize with custom distributions\n",
    "# https://www.projectrhea.org/rhea/index.php/MLE_Examples:_Exponential_and_Geometric_Distributions_Old_Kiwi\n",
    "\n",
    "from scipy.stats import geom, gamma\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def neg_loglike(theta):\n",
    "    prob = lambda x, y, z: -x * np.log(geom.pmf(y, z))\n",
    "    data = [10, 9, 8, 7, 6, 5]\n",
    "    return np.sum([prob(data[i], i+1, theta) for i in range(len(data))])\n",
    "\n",
    "theta_start = 0.5\n",
    "res = minimize(neg_loglike, theta_start, method = 'Nelder-Mead', options={'disp':True})\n",
    "print(res)\n",
    "\n",
    "print('------------')\n",
    "\n",
    "def weibull_cdf(t, l, c):\n",
    "    return 1 - math.exp(-l * (t**c))\n",
    "\n",
    "def weibull_2seg_2clust_withspike_negloglike(theta): #TODO: Implement correct function later\n",
    "    prob = lambda x, y, z: -x * np.log(gamma.pdf(y, z))\n",
    "    data = [10, 9, 8, 7, 6, 5]\n",
    "    return np.sum([prob(data[i], i+1, theta) for i in range(len(data))])\n",
    "\n",
    "param_start = 0.5\n",
    "res = minimize(weibull_2seg_2clust_withspike_negloglike, param_start, method = 'Nelder-Mead', options={'disp':True}) \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/scipy/scipy/issues/3056\n",
    "\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "X = np.array([[1.020626, 1.013055], [0.989094, 1.059343]])\n",
    "freq = 13.574380165289256\n",
    "x_0 = [1., 1.]\n",
    "\n",
    "def objective(b):\n",
    "    def foo(r_log, freq):\n",
    "        mu, sd = r_log.mean(), r_log.std()\n",
    "        sd += 0.5 / freq\n",
    "        return mu / sd * np.sqrt(freq)\n",
    "\n",
    "    print(b)\n",
    "    return -foo(np.log(np.maximum(np.dot(X - 1, b) + 1, 0.2)), freq=freq)\n",
    "\n",
    "cons = ({'type': 'ineq', 'fun': lambda b: 2. - sum(b)},)\n",
    "res = optimize.minimize(objective, x_0, bounds=[(0., 2.)]*len(x_0), constraints=cons, method='slsqp')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Poisson Regression\n",
    "# https://stackoverflow.com/questions/47686227/poisson-regression-in-statsmodels-and-r\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.formula.api\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Poisson\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(100, size=(50,2)))\n",
    "df.rename(columns={0:'X1', 1:'X2'}, inplace=True)\n",
    "\n",
    "# glm = statsmodels.formula.api.gee\n",
    "# model = glm(\"X2 ~ X1\", groups=None, data=df, family=Poisson())\n",
    "# results = model.fit()\n",
    "# print(results.summary())\n",
    "\n",
    "# Add a column of ones for the intercept to create input X. This model is similar to R implementation\n",
    "X = np.column_stack( (np.ones((df.shape[0], 1)), df.X1) )\n",
    "y = df.X2\n",
    "print(sm.GLM(y, X, family = Poisson()).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models related to Faders work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Try implementing following papers using scipy, octave, tensorflow, pytorch\n",
    "#https://repository.upenn.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1048&context=wharton_research_scholars\n",
    "#https://pdfs.semanticscholar.org/d566/7b80c85b221aedf9c498fdd1d98a4478118b.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy data\n",
    "ts_data1 = np.array([8,7,6,5,4,3,3,3,3,4,5,6,7,8,9,10])\n",
    "ts_data2 = np.concatenate((5+ts_data1[0:8], ts_data1[8:]))\n",
    "ts_data3 = np.concatenate((ts_data1[0:8], 5+ts_data1[8:]))\n",
    "ts_data = np.array([ts_data1.cumsum(), ts_data2.cumsum(), ts_data3.cumsum()])\n",
    "ts_data = np.tile(ts_data,(5,1))\n",
    "\n",
    "# ts_data_context = np.array(['a','b','b','b','b','c','c','c','c','c','d','d','d','d','d','e'])\n",
    "print(len(ts_data)) #,len(ts_data_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "tot_num_clusters = 2 #num_clusters + 1\n",
    "num_samples = len(ts_data)\n",
    "num_customers_per_sample = list(map(lambda x : x.sum(), ts_data))\n",
    "\n",
    "clust_assign = np.random.randint(num_clusters, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
