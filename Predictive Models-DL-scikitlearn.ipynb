{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import sklearn.preprocessing\n",
    "import scipy.sparse\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy data for regression\n",
    "\n",
    "tmp_df = pd.DataFrame([['a',1,2],['b',3,4],['a',5,6],['b',7,8],['a',9,10],['b',11,12]])\n",
    "tmp_df.columns = ['c1','c2','c3']\n",
    "categorical_features = ['c1','c2']\n",
    "X_train = X_test = pd.get_dummies(tmp_df[categorical_features])\n",
    "Y_train = Y_test = tmp_df['c3']\n",
    "\n",
    "enc_dict = defaultdict(sklearn.preprocessing.LabelEncoder)\n",
    "ohe = sklearn.preprocessing.OneHotEncoder()\n",
    "tmp_le_df = tmp_df[categorical_features].apply(lambda x : enc_dict[x.name].fit_transform(x))\n",
    "ohe.fit(tmp_le_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample specific uncertainty intervals for regression models\n",
    "\n",
    "# clf = sklearn.linear_model.LinearRegression()\n",
    "# clf.fit(X_train, Y_train)\n",
    "# Y_predictions = clf.predict(X_test)\n",
    "# print(clf.coef_, clf.intercept_)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# ##Train/Test prediction intervals using statsmodel. Use bootstrap or below approaches\n",
    "# #Theory: https://onlinecourses.science.psu.edu/stat414/node/298/\n",
    "# #http://nbviewer.jupyter.org/gist/thatneat/10286720\n",
    "# #https://www.learndatasci.com/tutorials/predicting-housing-prices-linear-regression-using-python-pandas-statsmodels/\n",
    "# #https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n",
    "# #https://stats.stackexchange.com/questions/183230/bootstrapping-confidence-interval-from-a-regression-prediction\n",
    "\n",
    "# Using stats model\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "# re = sm.OLS(Y_train, X_train).fit()\n",
    "# print(re.summary())\n",
    "# print('-'*80)\n",
    "# prstd, iv_l, iv_u = wls_prediction_std(re)\n",
    "# print(prstd, iv_l, iv_u)\n",
    "# print('-'*80)\n",
    "# prstd, iv_l, iv_u = wls_prediction_std(re, X_train.iloc[0:2]) #Test set can be invoked through this approach\n",
    "# print(prstd, iv_l, iv_u)\n",
    "\n",
    "# Using bootstrap \n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "n_estimators = 50\n",
    "model = BaggingRegressor(sklearn.linear_model.LinearRegression(), n_estimators=n_estimators, bootstrap=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Inspecting uncertainty interval for a prediction at sample test point\n",
    "test_sample = np.array([[1,2,3]])\n",
    "res = []\n",
    "for m in model.estimators_:\n",
    "    res.append(m.predict(test_sample))\n",
    "pd.DataFrame(res).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding based Neural Network Regressor\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Input, Embedding, merge, Reshape, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "categorical_features = ['c1','c2']\n",
    "numeric_features = []\n",
    "predict_col_name = 'c3'\n",
    "all_cols = categorical_features\n",
    "\n",
    "## Reformatting train/test data for keras model\n",
    "\n",
    "tmp_X_train, tmp_X_test = tmp_df, tmp_df\n",
    "tmp_le_train_df = tmp_X_train[categorical_features].apply(lambda x: enc_dict[x.name].transform(x))\n",
    "tmp_le_test_df = tmp_X_test[categorical_features].apply(lambda x: enc_dict[x.name].transform(x))\n",
    "\n",
    "tmp_X_train_inp = []\n",
    "tmp_X_test_inp = []\n",
    "for c in all_cols:\n",
    "    tmp_X_train_inp.append(np.array(tmp_le_train_df[c]))\n",
    "    tmp_X_test_inp.append(np.array(tmp_le_test_df[c]))\n",
    "\n",
    "print('Train test shape:', tmp_le_train_df.shape, tmp_le_test_df.shape)\n",
    "tmp_num_feat = {}\n",
    "for col in categorical_features:\n",
    "    num_uniq_features = len(enc_dict[col].classes_)\n",
    "    print (col, num_uniq_features)\n",
    "    tmp_num_feat.update({col:num_uniq_features})  # Feature embedding based regression model using keras\n",
    "\n",
    "embedding_size = 5\n",
    "batch_size = 16\n",
    "\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=0)\n",
    "# tmp_model_save_dir = '/Users/maheshgoud/Desktop/'\n",
    "# tmp_model_save_filename = tmp_model_save_dir + 'model_tmp.h5'\n",
    "\n",
    "## Keras model implementation\n",
    "\n",
    "tmp_input_list = []\n",
    "tmp_embedding_list = []\n",
    "for idx, e_col in enumerate(all_cols):\n",
    "    tmp_input = Input(shape=(1,), dtype='int32', name=e_col)\n",
    "    tmp_embedding = Embedding(input_dim=tmp_num_feat[e_col], output_dim=embedding_size, input_length=1)(tmp_input)\n",
    "    tmp_input_list.append(tmp_input)\n",
    "    tmp_embedding_list.append(tmp_embedding)\n",
    "\n",
    "x = layers.concatenate(tmp_embedding_list)\n",
    "x = Reshape((len(tmp_embedding_list)*embedding_size,), name=\"reshape_one\")(x)\n",
    "x = Dense(64, activation='relu', name=\"dense_1\")(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(32, activation='relu', name=\"dense_2\")(x)\n",
    "tmp_model_output = Dense(1, activation='relu', name=\"dense_3\")(x)\n",
    "\n",
    "tmp_final_model = Model(input=tmp_input_list, output=tmp_model_output)\n",
    "print(tmp_final_model.summary())\n",
    "\n",
    "# mean_squared_error, mean_absolute_percentage_error, mean_squared_logarithmic_error\n",
    "tmp_final_model.compile(loss='mean_absolute_percentage_error', optimizer='adadelta') #metrics=['accuracy']\n",
    "tmp_final_model.fit(tmp_X_train_inp, Y_train.values, epochs=5, batch_size=batch_size, validation_split=0.1) #, callbacks=[early_stopping])\n",
    "\n",
    "# tmp_final_model.save(tmp_model_save_filename)\n",
    "\n",
    "Y_predictions = tmp_final_model.predict(tmp_X_test_inp, batch_size=batch_size)\n",
    "mean_absolute_percentage_error(Y_test.values, Y_predictions) #TODO: Double check\n",
    "\n",
    "# from ann_visualizer.visualize import ann_viz\n",
    "# ann_viz(tmp_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy data for classification\n",
    "\n",
    "tmp_df = pd.DataFrame([['a',1,0],['b',3,1],['a',5,0],['b',7,1],['a',9,0],['b',11,1]])\n",
    "tmp_df.columns = ['c1','c2','c3']\n",
    "categorical_features = ['c1','c2']\n",
    "\n",
    "X_train = X_test = pd.get_dummies(tmp_df[categorical_features])\n",
    "Y_train = Y_test = tmp_df['c3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation on single train/test split for inspecting confusion matrix\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=1e4)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "\n",
    "#Evaluate predictions\n",
    "score = 100.0*round(clf.score(X_test, Y_test),4)\n",
    "print('Accuracy:',score)\n",
    "print(sklearn.metrics.classification_report(Y_test, Y_predictions, target_names=['(0)','(1)']))\n",
    "cm = sklearn.metrics.confusion_matrix(Y_test, Y_predictions)\n",
    "print('ConfusionMatrix\\n',cm)\n",
    "\n",
    "#Color coded confusion matrix\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(title, size = 15)\n",
    "plt.show()\n",
    "\n",
    "#scikitplot can be used for roc curves. skipping for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow lr what if tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poisson, exp regression with constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
